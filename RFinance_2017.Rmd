---
title: "How Can Machines Learn to Trade?"
author: "Jerzy Pawlowski, NYU Tandon School of Engineering"
date: "May 19, 2017"
output:
  ioslides_presentation:
    widescreen: yes
  slidy_presentation: default
email: jp3900@nyu.edu
affiliation: NYU Tandon School of Engineering
abstract: 'How Can Machines Learn to Trade?'
---

<SCRIPT SRC='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></SCRIPT>
<SCRIPT>MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}})</SCRIPT>



## Abstract {.smaller}  

Machine learning has been successfuly applied to speech and image recognition, but has faced challenges in automated trading.  For example forecasting models which rely on historical prices have very poor performance, because asset returns have a very low signal to noise ratio.  As a result, model forecasts have large standard errors, making them difficult to apply in practice.  The problem is often exacerbated by the high dimensionality of many financial models, for example portfolio optimization.

We study several techniques which can help to reduce the problem of large standard errors, such as parameter regularization (shrinkage), dimensionality reduction, and ensembles of models.  We use bootstrap simulation to estimate the standard errors, and to quantify the effect of these techniques. 



## Backtesting a Machine Learning Model {.smaller}  

- The model is trained over the lookback window, and tested out-of-sample on future data. 

- The length of the lookback window determines how quickly the model adapts to new information.  

- Backtesting allows determining the optimal length of the lookback window.  

<img alt="backtesting" src="C:/Develop/R/lecture_slides/figure/backtest.png" width="1000" height="300" align="top"/>  



## Coin Flipping Model {.smaller}  

<img alt="coinflipping" src="C:/Develop/R/lecture_slides/figure/coinflipping.jpg" width="800" height="150" align="top"/>  

- <a href="http://labs.elmfunds.com/pastreturns/" target="_blank"> Victor Haghani </a> suggested a coin flipping model to illustrate the challenge of properly selecting a manager with skill, based on past performance.

- We can select a manager from several managers, but only one of them has skill, and the remaining are without skill.

- The skilled manager has a slightly greater probability of positive returns than negative ones, while the unskilled managers have a slightly greater probability of negative returns, so that the average performance of all the managers is zero.

- If the probability of positive returns is equal to $p > 0.5$, then the annual Sharpe ratio is equal to $\sqrt{250}*(2p-1)$.

- If the excess annual Sharpe ratio is equal to $0.4$, then the probability of positive returns is equal to $(0.4/\sqrt{250}+1)/2 = 51.2\%$.



## Probability of Selecting a Biased Coin {.smaller}  

- We have a set of unbiased coins, except for a single biased one, with a $60\%$ probability of heads.

- We flip the coins simultaneously $n$ times, and select the coin that produces the most heads.  

- What is the probability of selecting the biased coin, after flipping the coins simultaneously $n$ times?  
<br>


```{r eval=TRUE, echo=FALSE, fig.width=5.5, fig.height=3.5}
# Calculate the probability of selecting the biased coin, as a function of the number of coin flips, and the number of coins.
confi_dence <- function(num_flips, num_coins, p1, p2=0.5) {
  # calculate binomial probabilities for biased coin, using normal approximation for the binomial coefficient.
  if (p1^num_flips > 1e-10)
    binom_1 <- choose(num_flips, 0:num_flips) * p1^(0:num_flips) * (1-p1)^(num_flips:0)
  else
    binom_1 <- dnorm(0:num_flips, mean=num_flips*p1, sd=sqrt(num_flips*p1*(1-p1)))
  # calculate binomial probabilities for unbiased coins, using normal approximation for the binomial coefficient.
  if (p2^num_flips > 1e-10)
    binom_2 <- choose(num_flips, 0:num_flips) * p2^(0:num_flips) * (1-p2)^(num_flips:0)
  else
    binom_2 <- dnorm(0:num_flips, mean=num_flips*p2, sd=sqrt(num_flips*p2*(1-p2)))
  # probability of unbiased coin producing less than a certain number of heads
  cum_binom_2 <- cumsum(binom_2)
  cum_binom_2 <- c(0, cum_binom_2[-NROW(cum_binom_2)])
# probability of selecting the biased coin, when there's a tie in number of heads
  prob_tie <- sapply(binom_2, function(pro_b)
    sum(choose(num_coins-1, 1:(num_coins-1)) * pro_b^(1:(num_coins-1)) * (1-pro_b)^((num_coins-2):0) / (2:num_coins)))
# total probability of selecting the biased coin, including ties in number of heads
  sum(binom_1 * (cum_binom_2^(num_coins-1) + prob_tie))
}  # end confi_dence

# Probability of selecting the biased coin out of 2 coins, after 132 coin flips
# confi_dence(132, num_coins=2, 0.6, 0.5)

# Probabilities of selecting the biased coin, as a function of the number of coin flips
num_flips <- 10:150
prob_s <- sapply(num_flips, confi_dence, p1=0.6, num_coins=2)
# Number of coin flips needed to select the biased coin, with 95% confidence
min_num_flips <- num_flips[findInterval(0.95, prob_s)]
# min_num_flips

# Plot probabilities as a function of the number of coin flips
# Create data frame
da_ta <- data.frame(num_flips=num_flips, probs=prob_s)
# Plot with plotly using pipes syntax
suppressMessages(suppressWarnings(library(plotly)))
da_ta %>% 
  plot_ly(x=~num_flips, y=~probs, type="scatter", mode="lines + markers", name="probability") %>% 
  add_trace(x=range(num_flips), y=0.95, mode="lines", line=list(color="red"), name="95% confidence") %>% 
  add_trace(x=min_num_flips, y=range(prob_s), mode="lines", line=list(color="green"), name=paste(min_num_flips, "flips")) %>% 
  layout(title="Probability of selecting biased coin from two coins", 
         xaxis=list(title="number of coin flips"),
         yaxis=list(title="probability"),
         legend=list(x=0.1, y=0.1))
```



## Probability of Selecting a Skilled Manager {.smaller}  

- What is the probability of selecting the skilled manager (with an excess Sharpe ratio of $0.4$), from among two managers?  

- $33$ years of data are needed to select the manager with skill, at $95\%$ confidence!  
<br>

```{r eval=TRUE, echo=FALSE, fig.width=5.5, fig.height=3.5}
# Sharpe ratio as function of daily probability
# sharpe_ratio <- sqrt(250)*(2*pro_b-1)
# Daily probability as function of Sharpe ratio
sharpe_ratio <- 0.4
pro_b <- (sharpe_ratio/sqrt(250)+1)/2
# Adjust probability to account for two managers
# pro_b <- 0.5 + (pro_b-0.5)/2

# Probability of selecting skilled manager with 20 years of data
# confi_dence(20*250, 2, pro_b, 0.5)

# Annual probabilities of selecting skilled manager from two managers
year_s <- 1:50
prob_s <- sapply(250*year_s, confi_dence, num_coins=2, p1=pro_b, p2=0.5)

# Years of data needed to select the skilled manager, with 95% confidence
num_years <- findInterval(0.95, prob_s)

# Plot probabilities as a function of the number of years
da_ta <- data.frame(years=year_s, probs=prob_s)
# Plot with plotly using pipes syntax
da_ta %>% 
  plot_ly(x=~years, y=~probs, type="scatter", mode="lines + markers", name="probability") %>% 
  add_trace(x=range(year_s), y=0.95, mode="lines", line=list(color="red"), name="95% confidence") %>% 
  add_trace(x=num_years, y=range(prob_s), mode="lines", line=list(color="green"), name=paste(num_years, "years")) %>% 
  layout(title="Probability of selecting skilled manager", 
         xaxis=list(title="years"),
         yaxis=list(title="probabilities"),
         legend=list(x=0.1, y=0.1))
```



## Selecting From Among Multiple Managers {.smaller}  

- In reality we must select from among multiple managers, any one of whom may out-perform purely by chance.  
<br>

```{r eval=TRUE, echo=FALSE, fig.width=5.5, fig.height=3.5}
# Probabilities of selecting the skilled manager, as a function of the number of managers
num_managers <- 2:50
prob_s <- sapply(num_managers, confi_dence, p1=pro_b, p2=0.5, num_flips=250*33)
# prob_s <- cbind(num_managers, prob_s)
# plot(prob_s, t="l", main="Probabilities of selecting the skilled manager, as a function of the number of managers")

# Create data frame
da_ta <- data.frame(num_managers=num_managers, probs=prob_s)
# Plot with plotly using pipes syntax
da_ta %>% 
  plot_ly(x=~num_managers, y=~probs, type="scatter", mode="lines + markers", name="probability") %>% 
  layout(title="Probability of selecting skilled manager, from multiple managers", 
         xaxis=list(title="number of managers"),
         yaxis=list(title="probability"),
         legend=list(x=0.1, y=0.1))
```



## False Discovery Rate Problem {.smaller}  

- p-hacking or false-discovery rate problem:
What is the probability of obtaining a very large number of heads?
plot probability as function of number of coins

- If we Flip Many Coins Then We Will Always Find One That We Think is Biased

In practice we're faced with a much more difficult problem of choosing among many different strategies.
Let's imagine we flip many coins.
We Will Always Find One That We Think is Biased

potential solution of false-discovery rate problem:
control the false-discovery rate using Bonferroni method Sidak correction  
increase p-value
not a good solution

another solution: shrink space of strategies to choose from
we suffer from bias (we don't choose the best strategy)
but we gain from lower variance

We're allowed to select a fixed number of coins at random, and then to flip them together a fixed number of times.
How many coins should we select at random, in order too maximize our chances of selecting the biased coin?

another solution: increase the amount of data - use minutely data - but doesn't work

```{r eval=FALSE, echo=FALSE, fig.width=5.5, fig.height=3.5}
# Probability of selecting the biased coin out of 2 coins, after 132 coin flips
# confi_dence(132, num_coins=2, 0.6, 0.5)

# Number of coin flips needed to select the biased coin, with 95% confidence
# num_flips <- 100:150
# prob_s <- sapply(num_flips, confi_dence, p1=0.6, num_coins=2)
# min_num_flips <- num_flips[findInterval(0.95, prob_s)]
# min_num_flips

# Probabilities of selecting the biased coin, as a function of the number of coins
num_coins <- 2:50
prob_s <- sapply(num_coins, confi_dence, p1=0.6, num_flips=50)
# prob_s <- cbind(num_coins, prob_s)
# plot(prob_s, t="l", main="Probabilities of selecting the biased coin, as a function of the number of coins")

# Load plotly
suppressMessages(suppressWarnings(library(plotly)))
# Create data frame
da_ta <- data.frame(num_coins=num_coins, probs=prob_s)
# Plot with plotly using pipes syntax
da_ta %>% 
  plot_ly(x=~num_coins, y=~probs, type="scatter", mode="lines + markers", name="probability") %>% 
  layout(title="Probability of selecting biased coin, from a number of coins", 
         xaxis=list(title="number of coins"),
         yaxis=list(title="probability"),
         legend=list(x=0.1, y=0.1))

```



## Dynamic Investing With Multiple Managers {.smaller}  

- Dynamic strategy: at the end of each period, we switch to the best performing manager.  
<br>


<img alt="backtesting" src="C:/Develop/R/lecture_slides/figure/backtest.png" width="1000" height="300" align="top"/>  



## Effect of Number of Managers {.smaller}  

- A greater number of managers decreases the out-of-sample strategy performance.  
<br>

```{r eval=TRUE, echo=FALSE, fig.width=5.5, fig.height=3.5}
# cum_pnl for multi-manager strategy (simplest version)
cum_pnl <- function(look_back, n_row, sharpe_ratio=NULL, re_turns=NULL, mean_s=NULL, num_managers=NULL, vol_at=0.01) {
  # calculate drifts
  if(is.null(mean_s)) {
    pro_b <- (sharpe_ratio/sqrt(250)+1)/2
    # Adjust probability to account for multiple managers
    p1 <- (0.5*num_managers + (pro_b - 0.5)*(num_managers-1)) / num_managers
    p2 <- (0.5*num_managers - (pro_b - 0.5)) / num_managers
    mean_s <- vol_at*look_back*c(2*p1-1, rep(2*p2-1, num_managers-1))
  } else {
    num_managers <- NROW(mean_s)
  }  # end if
  # calculate probability of selecting the best manager
  pro_b <- integrate(function(x, ...) 
    dnorm(x, mean=mean_s[1], ...)*pnorm(x, mean=mean_s[2], ...)^(num_managers-1), 
            low=-3.0, up=3.0, 
            sd=sqrt(look_back)*vol_at)$value
  # return total expected pnl
  num_agg <- n_row %/% look_back
  num_agg*(pro_b*mean_s[1] + (1-pro_b)*mean_s[2])
}  # end cum_pnl

# Calculate total expected pnl
# cum_pnl(look_back=100, sharpe_ratio=0.4, num_managers=11, n_row=5000)

# Perform loop over number of managers
num_managers <- 2*(1:50)
pnl_s <- sapply(num_managers, cum_pnl, 
              re_turns=NULL, sharpe_ratio=0.4, look_back=100, n_row=50000, mean_s=NULL, vol_at=0.01)
# pnl_s <- cbind(num_managers, pnl_s)
# plot(pnl_s, t="l", main="Strategy pnl as a function of number of managers")

# Create data frame
da_ta <- data.frame(num_managers=num_managers, pnl_s=pnl_s)
# Plot with plotly using pipes syntax
da_ta %>% 
  plot_ly(x=~num_managers, y=~pnl_s, type="scatter", mode="lines + markers", name="probability") %>% 
  layout(title="Strategy pnl as function of number of managers", 
         xaxis=list(title="number of managers"),
         yaxis=list(title="strategy pnl"),
         legend=list(x=0.1, y=0.1))
```



## Effect of Lookback Window Length {.smaller}  

- A longer lookback window increases the out-of-sample strategy performance.  
<br>

```{r eval=TRUE, echo=FALSE, fig.width=5.5, fig.height=3.5}
# Perform loop over look-back windows
look_backs <- 100*(1:20)
pnl_s <- sapply(look_backs, cum_pnl, 
              sharpe_ratio=0.4, num_managers=11, n_row=50000)
# pnl_s <- cbind(look_backs, pnl_s)
# plot(pnl_s, t="l", main="Strategy pnl as a function of lookback window length")

# Create data frame
da_ta <- data.frame(look_backs=look_backs, pnl_s=pnl_s)
# Plot with plotly using pipes syntax
da_ta %>% 
  plot_ly(x=~look_backs, y=~pnl_s, type="scatter", mode="lines + markers", name="probability") %>% 
  layout(title="Strategy pnl as function of lookback window length", 
         xaxis=list(title="window length"),
         yaxis=list(title="strategy pnl"),
         legend=list(x=0.1, y=0.1))
```



## Lookback Window Size {.smaller}  

- How long should the lookback window be, to avoid training a model on noise?  



## How Much Data is Needed to Decide Which Strategy is Best? {.smaller}  

in real world return distributions are not stationary and drifts aren't static
time-varying drift (alpha)
simulate asset returns with static drifts plus a random noise.
Model with static drifts
Higher volatility requires more data
use $1\%$ daily vol and daily drift equal to $0.031\%$


## How Much Data is Needed to Learn Which Strategy is Best? {.smaller}  

simulate asset returns with time-dependent drifts plus a random noise.
bias-variance tradeoff
optimal length of the lookback interval
Higher volatility requires longer lookback interval
faster drift requires shorter lookback interval

use $1\%$ daily vol and daily drift equal to $0.031\%$

first conclusion is that we need to use minutely data
daily data isn't sufficient to switch between strategies

second conclusion is that we need to use shrinkage



## How Much Data is Needed to Learn Which Strategy is Best? {.smaller}  

Performance of strategies is time-dependent
Switching between strategies


